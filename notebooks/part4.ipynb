{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de852535-7dbd-4dd6-93b2-1df69e1acfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import os\n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.query import BatchStatement\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pymongo.mongo_client import MongoClient\n",
    "from pymongo.server_api import ServerApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7636b2a5-7f64-41a9-8419-1fca7e80c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the environment for PySpark\n",
    "load_dotenv()\n",
    "\n",
    "HADOOP_PATH = os.getenv(\"HADOOP_PATH\")\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = r\"C:\\Program Files\\Microsoft\\jdk-11.0.28.6-hotspot\" \n",
    "os.environ[\"PYSPARK_HADOOP_VERSION\"] = \"without\"\n",
    "os.environ[\"HADOOP_HOME\"] = HADOOP_PATH\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f6e6b12-6781-4ec3-9a43-940f9901ae01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pinged your deployment. You successfully connected to MongoDB!\n"
     ]
    }
   ],
   "source": [
    "# Setting the environment for MongoDB\n",
    "load_dotenv()\n",
    "\n",
    "USR,PWD = os.getenv(\"DB_USER\"), os.getenv(\"DB_PWD\")\n",
    "\n",
    "uri = f\"mongodb+srv://{USR}:{PWD}@ind320.nxw58bh.mongodb.net/?retryWrites=true&w=majority&appName=IND320\"\n",
    "\n",
    "# Create a client and connect to the server\n",
    "client = MongoClient(uri, server_api=ServerApi('1'))\n",
    "\n",
    "# Send a ping to confirm a successful connection\n",
    "try:\n",
    "    client.admin.command('ping')\n",
    "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93a60d5-befb-4673-9191-8c2a6b3bc214",
   "metadata": {},
   "source": [
    "# Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5c4abf-dcc7-4802-880a-5cd7ec799ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the environment for collecting the elhub-data for 2021-01-01\n",
    "entity = 'price-areas'\n",
    "dataset = 'PRODUCTION_PER_GROUP_MBA_HOUR'\n",
    "start = '2021-01-01T00:00:00%2B02:00'\n",
    "end = '2021-01-01T23:59:59%2B02:00' \n",
    "res = requests.get(f'https://api.elhub.no/energy-data/v0/{entity}?dataset={dataset}&startDate={start}&endDate={end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0fca84-66f0-4d39-9d4c-f598c2ed8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that we got a connection to the API\n",
    "assert res.status_code == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5750efbb-cf86-4987-a005-858c71bb6317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date            : Mon, 17 Nov 2025 15:29:22 GMT\n",
      "Content-Type    : application/json; charset=utf-8\n",
      "Transfer-Encoding: chunked\n",
      "Connection      : keep-alive\n",
      "Cache-Control   : public, max-age=3600\n",
      "strict-transport-security: max-age=63072000; includeSubDomains\n"
     ]
    }
   ],
   "source": [
    "for header_name, header_value in res.headers.items():\n",
    "    print(f'{header_name:16s}: {header_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26d42816-d023-465f-b1db-0c732fbdf0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-01T00:00:00%2B02:00\n",
      "2022-02-01T00:00:00%2B02:00\n",
      "2022-03-01T00:00:00%2B02:00\n",
      "2022-04-01T00:00:00%2B02:00\n",
      "2022-05-01T00:00:00%2B02:00\n",
      "2022-06-01T00:00:00%2B02:00\n",
      "2022-07-01T00:00:00%2B02:00\n",
      "2022-08-01T00:00:00%2B02:00\n",
      "2022-09-01T00:00:00%2B02:00\n",
      "2022-10-01T00:00:00%2B02:00\n",
      "2022-11-01T00:00:00%2B02:00\n",
      "2022-12-01T00:00:00%2B02:00\n",
      "2023-01-01T00:00:00%2B02:00\n",
      "2023-02-01T00:00:00%2B02:00\n",
      "2023-03-01T00:00:00%2B02:00\n",
      "2023-04-01T00:00:00%2B02:00\n",
      "2023-05-01T00:00:00%2B02:00\n",
      "2023-06-01T00:00:00%2B02:00\n",
      "2023-07-01T00:00:00%2B02:00\n",
      "2023-08-01T00:00:00%2B02:00\n",
      "2023-09-01T00:00:00%2B02:00\n",
      "2023-10-01T00:00:00%2B02:00\n",
      "2023-11-01T00:00:00%2B02:00\n",
      "2023-12-01T00:00:00%2B02:00\n",
      "2024-01-01T00:00:00%2B02:00\n",
      "2024-02-01T00:00:00%2B02:00\n",
      "2024-03-01T00:00:00%2B02:00\n",
      "2024-04-01T00:00:00%2B02:00\n",
      "2024-05-01T00:00:00%2B02:00\n",
      "2024-06-01T00:00:00%2B02:00\n",
      "2024-07-01T00:00:00%2B02:00\n",
      "2024-08-01T00:00:00%2B02:00\n",
      "2024-09-01T00:00:00%2B02:00\n",
      "2024-10-01T00:00:00%2B02:00\n",
      "2024-11-01T00:00:00%2B02:00\n",
      "2024-12-01T00:00:00%2B02:00\n"
     ]
    }
   ],
   "source": [
    "# Creating a list which we will extend with dataframes each containing data for one month\n",
    "data = []\n",
    "\n",
    "# Creating start and stop dates for the api call and collecting data\n",
    "years = [2022, 2023, 2024]\n",
    "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "for year in years:\n",
    "    for month in months:\n",
    "        if month < 9:\n",
    "            start = f'{year}-0{month}-01T00:00:00%2B02:00'\n",
    "            end = f'{year}-0{month+1}-01T00:00:00%2B02:00'\n",
    "        elif month == 9:\n",
    "            start = f'{year}-0{month}-01T00:00:00%2B02:00'\n",
    "            end = f'{year}-{month+1}-01T00:00:00%2B02:00'\n",
    "        elif month == 12:\n",
    "            start = f'{year}-{month}-01T00:00:00%2B02:00'\n",
    "            end = f'{year}-{month}-31T23:59:59%2B02:00'\n",
    "        else: \n",
    "            start = f'{year}-{month}-01T00:00:00%2B02:00'\n",
    "            end = f'{year}-{month+1}-01T00:00:00%2B02:00'\n",
    "        print(start)\n",
    "        res = requests.get(f'https://api.elhub.no/energy-data/v0/{entity}?dataset={dataset}&startDate={start}&endDate={end}')\n",
    "        assert res.status_code == 200\n",
    "        payload = res.json()\n",
    "        temp_data = [pd.DataFrame(entry['attributes']['productionPerGroupMbaHour'])\n",
    "                 for entry in payload['data']]\n",
    "        data.extend(temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a83b31d1-d95b-411f-a830-edefecaab842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make one datafram from the list of dataframes collected\n",
    "df = pd.concat(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fff4148-e703-4311-bf07-e5fe84702336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endTime</th>\n",
       "      <th>lastUpdatedTime</th>\n",
       "      <th>priceArea</th>\n",
       "      <th>productionGroup</th>\n",
       "      <th>quantityKwh</th>\n",
       "      <th>startTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01T01:00:00+01:00</td>\n",
       "      <td>2025-02-01T18:02:57+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1291422.4</td>\n",
       "      <td>2022-01-01T00:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01T02:00:00+01:00</td>\n",
       "      <td>2025-02-01T18:02:57+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1246209.4</td>\n",
       "      <td>2022-01-01T01:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01T03:00:00+01:00</td>\n",
       "      <td>2025-02-01T18:02:57+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1271757.0</td>\n",
       "      <td>2022-01-01T02:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01T04:00:00+01:00</td>\n",
       "      <td>2025-02-01T18:02:57+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1204251.8</td>\n",
       "      <td>2022-01-01T03:00:00+01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01T05:00:00+01:00</td>\n",
       "      <td>2025-02-01T18:02:57+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1202086.9</td>\n",
       "      <td>2022-01-01T04:00:00+01:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     endTime            lastUpdatedTime priceArea  \\\n",
       "0  2022-01-01T01:00:00+01:00  2025-02-01T18:02:57+01:00       NO1   \n",
       "1  2022-01-01T02:00:00+01:00  2025-02-01T18:02:57+01:00       NO1   \n",
       "2  2022-01-01T03:00:00+01:00  2025-02-01T18:02:57+01:00       NO1   \n",
       "3  2022-01-01T04:00:00+01:00  2025-02-01T18:02:57+01:00       NO1   \n",
       "4  2022-01-01T05:00:00+01:00  2025-02-01T18:02:57+01:00       NO1   \n",
       "\n",
       "  productionGroup  quantityKwh                  startTime  \n",
       "0           hydro    1291422.4  2022-01-01T00:00:00+01:00  \n",
       "1           hydro    1246209.4  2022-01-01T01:00:00+01:00  \n",
       "2           hydro    1271757.0  2022-01-01T02:00:00+01:00  \n",
       "3           hydro    1204251.8  2022-01-01T03:00:00+01:00  \n",
       "4           hydro    1202086.9  2022-01-01T04:00:00+01:00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "303665fd-3119-48ba-926b-d34bca1edd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(657600, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd539c8d-3c97-487a-aa97-0a746e84f3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(657600, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates if there were any duplicates created at the start/end of months \n",
    "df = df.drop_duplicates()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70b3dbf1-4a6d-4cb3-a4e9-ab0a84924cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "endTime             object\n",
       "lastUpdatedTime     object\n",
       "priceArea           object\n",
       "productionGroup     object\n",
       "quantityKwh        float64\n",
       "startTime           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking datatypes and converting datetime columns to type datetime\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc2303d-f8a5-4fca-a596-dc9ce34b0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['endTime'] = pd.to_datetime(df['endTime'], utc=True).dt.tz_localize(None)\n",
    "df['lastUpdatedTime'] = pd.to_datetime(df['lastUpdatedTime'], utc=True).dt.tz_localize(None)\n",
    "df['startTime'] = pd.to_datetime(df['startTime'], utc=True).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e704e616-4318-4bde-90f7-156c45a87474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "endTime            datetime64[ns]\n",
       "lastUpdatedTime    datetime64[ns]\n",
       "priceArea                  object\n",
       "productionGroup            object\n",
       "quantityKwh               float64\n",
       "startTime          datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53762fb-01e5-447c-905f-d79ab978ac63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9aad0bf-2221-4dcb-9816-02bfc0a5c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Casseandra environment\n",
    "keyspace = 'my_first_keyspace'\n",
    "table_name = 'elhub'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45550c8e-2342-4ded-aa79-0057478bfb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting pandas datatypes to Cassandra compatible datatypes\n",
    "def pandas_to_cassandra_type(dtype):\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return 'int'\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return 'double'\n",
    "    elif np.issubdtype(dtype, np.datetime64):\n",
    "        return 'timestamp'\n",
    "    else:\n",
    "        return 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd09595-7a7a-40be-9619-889c18368d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to Cassandra\n",
    "cluster = Cluster(['localhost'], port=9042)\n",
    "session = cluster.connect()\n",
    "session.set_keyspace(f'{keyspace}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09eb2c6e-1f29-43a4-9a68-5ed55099f632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'endTime timestamp, lastUpdatedTime timestamp, priceArea text, productionGroup text, quantityKwh double, startTime timestamp, row_id int'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting column definitions for Cassandra\n",
    "columns_cql = ', '.join([\n",
    "    f'{col} {pandas_to_cassandra_type(df[col].dtype)}'\n",
    "    for col in columns\n",
    "])\n",
    "columns_cql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a06b8e30-72c2-40e5-9b15-609d88b9d915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215353"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read max row_id from Cassandra db to start inserting data with row ids starting after max row_id\n",
    "result = session.execute(\"SELECT max(row_id) FROM elhub\")\n",
    "max_id = result.one()[0]\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4873056b-4ec6-4bb8-8461-18564bcd41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('row_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f9924fb-d9fc-478d-a6c8-265037abac26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endTime</th>\n",
       "      <th>lastUpdatedTime</th>\n",
       "      <th>priceArea</th>\n",
       "      <th>productionGroup</th>\n",
       "      <th>quantityKwh</th>\n",
       "      <th>startTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2025-02-01 17:02:57</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1291422.4</td>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>2025-02-01 17:02:57</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1246209.4</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>2025-02-01 17:02:57</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1271757.0</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>2025-02-01 17:02:57</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1204251.8</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>2025-02-01 17:02:57</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1202086.9</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              endTime     lastUpdatedTime priceArea productionGroup  \\\n",
       "0 2022-01-01 00:00:00 2025-02-01 17:02:57       NO1           hydro   \n",
       "1 2022-01-01 01:00:00 2025-02-01 17:02:57       NO1           hydro   \n",
       "2 2022-01-01 02:00:00 2025-02-01 17:02:57       NO1           hydro   \n",
       "3 2022-01-01 03:00:00 2025-02-01 17:02:57       NO1           hydro   \n",
       "4 2022-01-01 04:00:00 2025-02-01 17:02:57       NO1           hydro   \n",
       "\n",
       "   quantityKwh           startTime  \n",
       "0    1291422.4 2021-12-31 23:00:00  \n",
       "1    1246209.4 2022-01-01 00:00:00  \n",
       "2    1271757.0 2022-01-01 01:00:00  \n",
       "3    1204251.8 2022-01-01 02:00:00  \n",
       "4    1202086.9 2022-01-01 03:00:00  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b85ccd6d-289d-4990-ba6e-b0d7a71276b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endTime</th>\n",
       "      <th>lastUpdatedTime</th>\n",
       "      <th>priceArea</th>\n",
       "      <th>productionGroup</th>\n",
       "      <th>quantityKwh</th>\n",
       "      <th>startTime</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>2025-02-01 17:02:57</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1291422.4</td>\n",
       "      <td>2021-12-31 23:00:00</td>\n",
       "      <td>215354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>2025-02-01 17:02:57</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1246209.4</td>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>215355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>2025-02-01 17:02:57</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1271757.0</td>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>215356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>2025-02-01 17:02:57</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1204251.8</td>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>215357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>2025-02-01 17:02:57</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>1202086.9</td>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>215358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              endTime     lastUpdatedTime priceArea productionGroup  \\\n",
       "0 2022-01-01 00:00:00 2025-02-01 17:02:57       NO1           hydro   \n",
       "1 2022-01-01 01:00:00 2025-02-01 17:02:57       NO1           hydro   \n",
       "2 2022-01-01 02:00:00 2025-02-01 17:02:57       NO1           hydro   \n",
       "3 2022-01-01 03:00:00 2025-02-01 17:02:57       NO1           hydro   \n",
       "4 2022-01-01 04:00:00 2025-02-01 17:02:57       NO1           hydro   \n",
       "\n",
       "   quantityKwh           startTime  row_id  \n",
       "0    1291422.4 2021-12-31 23:00:00  215354  \n",
       "1    1246209.4 2022-01-01 00:00:00  215355  \n",
       "2    1271757.0 2022-01-01 01:00:00  215356  \n",
       "3    1204251.8 2022-01-01 02:00:00  215357  \n",
       "4    1202086.9 2022-01-01 03:00:00  215358  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['row_number'] = range(1, len(df)+1)\n",
    "primary_key = columns[-1]\n",
    "df['row_id'] = max_id + df['row_number']\n",
    "df = df.drop('row_number', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "250daffc-913e-4ff0-b76d-845760df96cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bulk insert completed\n"
     ]
    }
   ],
   "source": [
    "# Inserting data into Cassandra using batch-insert \n",
    "columns = list(df.columns)\n",
    "placeholders = \", \".join([\"?\"] * len(columns))\n",
    "columns_str = \", \".join(columns)\n",
    "\n",
    "insert_cql = f\"INSERT INTO elhub ({columns_str}) VALUES ({placeholders})\"\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "prepared = session.prepare(insert_cql)\n",
    "batch = BatchStatement()\n",
    "\n",
    "for i, (_, row) in enumerate(df.iterrows(), 1):\n",
    "    values = [v.to_pydatetime() if isinstance(v, pd.Timestamp) else v for v in row]\n",
    "    batch.add(prepared, tuple(values))\n",
    "\n",
    "    if i % BATCH_SIZE == 0:\n",
    "        session.execute(batch)\n",
    "        batch = BatchStatement()  # reset batch\n",
    "\n",
    "# execute remaining\n",
    "if len(batch) > 0:\n",
    "    session.execute(batch)\n",
    "\n",
    "print(\"Bulk insert completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c298e06b-e9b1-4c2f-a665-aaf6718d0821",
   "metadata": {},
   "source": [
    "# Reading data from Cassandra using Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab330279-9acc-4fb8-853f-0cb8a4707d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a Spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName('CassandraReader')\n",
    "    .config('spark.jars.packages', 'com.datastax.spark:spark-cassandra-connector_2.12:3.4.1')\n",
    "    .config('spark.cassandra.connection.host', 'localhost')  \n",
    "    .config('spark.cassandra.connection.port', '9042')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "251422f8-8743-420d-a677-a2ebc3611bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the data from the Cassandra database\n",
    "df = (\n",
    "    spark.read\n",
    "    .format('org.apache.spark.sql.cassandra')\n",
    "    .options(table='elhub', keyspace='my_first_keyspace')\n",
    "    .load()\n",
    "    .select('pricearea', 'productiongroup', 'starttime', 'quantitykwh')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec65636f-6a81-4359-ba66-3278499c3b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(872953, 4)\n"
     ]
    }
   ],
   "source": [
    "# Check the dimensions of the data from Cassandra. Looks like the df is 4 times as long, good.\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f620f96d-1c7e-4481-881f-89b544d5a100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+-------------------+-----------+\n",
      "|pricearea|productiongroup|          starttime|quantitykwh|\n",
      "+---------+---------------+-------------------+-----------+\n",
      "|      NO3|          hydro|2024-05-07 21:00:00|  2676882.2|\n",
      "|      NO1|          solar|2022-02-10 12:00:00|   2922.939|\n",
      "|      NO1|          other|2023-08-25 20:00:00|     16.362|\n",
      "|      NO5|          other|2024-09-15 12:00:00|     15.321|\n",
      "|      NO2|          solar|2024-04-11 00:00:00|     42.247|\n",
      "|      NO5|        thermal|2022-10-10 18:00:00|    16207.0|\n",
      "|      NO1|        thermal|2024-07-22 15:00:00|  21147.885|\n",
      "|      NO2|        thermal|2021-04-25 02:00:00|   25452.85|\n",
      "|      NO3|        thermal|2022-08-03 16:00:00|    18202.0|\n",
      "|      NO1|          hydro|2022-08-30 17:00:00|  1317006.4|\n",
      "|      NO4|          hydro|2021-04-26 03:00:00|  2285321.8|\n",
      "|      NO3|          other|2023-05-02 20:00:00|     42.152|\n",
      "|      NO2|          other|2021-02-26 19:00:00|      3.822|\n",
      "|      NO3|          hydro|2021-07-02 08:00:00|  2796627.8|\n",
      "|      NO5|           wind|2021-11-08 08:00:00|        0.0|\n",
      "|      NO1|          other|2023-05-19 09:00:00|     70.067|\n",
      "|      NO2|          other|2021-05-28 17:00:00|    262.672|\n",
      "|      NO1|          hydro|2024-08-21 08:00:00|  2707635.5|\n",
      "|      NO1|          other|2022-08-24 06:00:00|     45.814|\n",
      "|      NO2|        thermal|2021-11-03 20:00:00|  15621.884|\n",
      "+---------+---------------+-------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking that the data looks ok\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da902f9-6520-4704-b0ea-77d95c1a7ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(pricearea='NO5', productiongroup='wind', starttime=datetime.datetime(2024, 12, 31, 23, 0), quantitykwh=0.0),\n",
       " Row(pricearea='NO5', productiongroup='wind', starttime=datetime.datetime(2024, 12, 31, 22, 0), quantitykwh=0.0),\n",
       " Row(pricearea='NO5', productiongroup='wind', starttime=datetime.datetime(2024, 12, 31, 21, 0), quantitykwh=0.0),\n",
       " Row(pricearea='NO5', productiongroup='wind', starttime=datetime.datetime(2024, 12, 31, 20, 0), quantitykwh=0.0),\n",
       " Row(pricearea='NO5', productiongroup='wind', starttime=datetime.datetime(2024, 12, 31, 19, 0), quantitykwh=0.0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets also look at the tail of the data. Both head and tail looks good.\n",
    "df.orderBy(\"row_id\", ascending=False).limit(5).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b7d25-93c8-4775-9fce-29a9b3d59116",
   "metadata": {},
   "source": [
    "# Inserting data to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ed1f97-b1a7-412e-9bba-293fd9ddefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the Spark datafram to a pandas dataframe\n",
    "pdf = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ce75cd-4da7-448a-88a4-5d5bd3abffe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pricearea</th>\n",
       "      <th>productiongroup</th>\n",
       "      <th>starttime</th>\n",
       "      <th>quantitykwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO1</td>\n",
       "      <td>other</td>\n",
       "      <td>2022-10-03 06:00:00</td>\n",
       "      <td>11.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NO4</td>\n",
       "      <td>thermal</td>\n",
       "      <td>2021-12-13 22:00:00</td>\n",
       "      <td>20695.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO2</td>\n",
       "      <td>wind</td>\n",
       "      <td>2022-05-27 11:00:00</td>\n",
       "      <td>569478.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO2</td>\n",
       "      <td>solar</td>\n",
       "      <td>2022-10-27 14:00:00</td>\n",
       "      <td>3084.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2024-09-21 02:00:00</td>\n",
       "      <td>2692534.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pricearea productiongroup           starttime  quantitykwh\n",
       "0       NO1           other 2022-10-03 06:00:00       11.300\n",
       "1       NO4         thermal 2021-12-13 22:00:00    20695.977\n",
       "2       NO2            wind 2022-05-27 11:00:00   569478.900\n",
       "3       NO2           solar 2022-10-27 14:00:00     3084.904\n",
       "4       NO1           hydro 2024-09-21 02:00:00  2692534.000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e212ad96-fde9-4b69-aaa6-587bc1fa6b63",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o60.save.\n: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: mongodb. Please find packages at `https://spark.apache.org/third-party-projects.html`.\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\r\n\tat org.apache.spark.sql.DataFrameWriter.lookupV2Provider(DataFrameWriter.scala:863)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:257)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\nCaused by: java.lang.ClassNotFoundException: mongodb.DefaultSource\r\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\r\n\tat scala.util.Failure.orElse(Try.scala:224)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\r\n\t... 16 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPy4JJavaError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m  \u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmongodb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m  \u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mappend\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m  \u001b[49m\u001b[43m.\u001b[49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatabase\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mIND320\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m  \u001b[49m\u001b[43m.\u001b[49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcollection\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mproduction_NO1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m  \u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\D2D_env\\Lib\\site-packages\\pyspark\\sql\\readwriter.py:1461\u001b[39m, in \u001b[36mDataFrameWriter.save\u001b[39m\u001b[34m(self, path, format, mode, partitionBy, **options)\u001b[39m\n\u001b[32m   1459\u001b[39m     \u001b[38;5;28mself\u001b[39m.format(\u001b[38;5;28mformat\u001b[39m)\n\u001b[32m   1460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1461\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_jwrite\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1462\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1463\u001b[39m     \u001b[38;5;28mself\u001b[39m._jwrite.save(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\D2D_env\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[39m, in \u001b[36mJavaMember.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m   1316\u001b[39m command = proto.CALL_COMMAND_NAME +\\\n\u001b[32m   1317\u001b[39m     \u001b[38;5;28mself\u001b[39m.command_header +\\\n\u001b[32m   1318\u001b[39m     args_command +\\\n\u001b[32m   1319\u001b[39m     proto.END_COMMAND_PART\n\u001b[32m   1321\u001b[39m answer = \u001b[38;5;28mself\u001b[39m.gateway_client.send_command(command)\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m return_value = \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[32m   1326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[33m\"\u001b[39m\u001b[33m_detach\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\D2D_env\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:179\u001b[39m, in \u001b[36mcapture_sql_exception.<locals>.deco\u001b[39m\u001b[34m(*a, **kw)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdeco\u001b[39m(*a: Any, **kw: Any) -> Any:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    181\u001b[39m         converted = convert_exception(e.java_exception)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\miniconda3\\envs\\D2D_env\\Lib\\site-packages\\py4j\\protocol.py:326\u001b[39m, in \u001b[36mget_return_value\u001b[39m\u001b[34m(answer, gateway_client, target_id, name)\u001b[39m\n\u001b[32m    324\u001b[39m value = OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[32m2\u001b[39m:], gateway_client)\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[32m1\u001b[39m] == REFERENCE_TYPE:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[32m    327\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    328\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name), value)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[32m    331\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.\n\u001b[32m    332\u001b[39m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, name, value))\n",
      "\u001b[31mPy4JJavaError\u001b[39m: An error occurred while calling o60.save.\n: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: mongodb. Please find packages at `https://spark.apache.org/third-party-projects.html`.\r\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:724)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\r\n\tat org.apache.spark.sql.DataFrameWriter.lookupV2Provider(DataFrameWriter.scala:863)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:257)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:248)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\nCaused by: java.lang.ClassNotFoundException: mongodb.DefaultSource\r\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\r\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\r\n\tat scala.util.Failure.orElse(Try.scala:224)\r\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\r\n\t... 16 more\r\n"
     ]
    }
   ],
   "source": [
    "# Inserting the data to MongoDB\n",
    "collection = client.IND320.production_NO1\n",
    "x = collection.insert_many(pdf.to_dict('records'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
